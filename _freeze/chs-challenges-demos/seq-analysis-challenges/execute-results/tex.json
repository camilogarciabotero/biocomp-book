{
  "hash": "bbab95291f34d024ab0de2a82e3ad7fa",
  "result": {
    "markdown": "---\nexecute: \n  freeze: auto\nfilters:\n  # - code-filename\n  - nutshell\n  - lightbox\n---\n\n\n# Seq. Analysis challenges {.unnumbered}\n\n## Counting features\n\nThe first step in this journey is to download a bunch of sequences programmatically. To do so, we will use the program [ncbi-genome-download](https://github.com/kblin/ncbi-genome-download).\n\nYou could inspect all the options it provides, now we will set our command as the following:\n\n```{.zsh}\n#| echo: true\n#| eval: false\nngd --genera \"Bacillus subtilis\"\\\n    -s refseq\\\n    -l complete\\\n    -o Data\\\n    --flat-output\\\n    --format features\\\n    -n bacteria\\\n    | head -n 5\n```\nTo this date this command will search for 216 complete genome information of *Bacillus subtilis* strains and download the **feature-table** file compressed. So the next step is to decompress all of them:\n\n```{.zsh}\nfor i in *.txt; do\n  gzip -d $i\ndone\n```\nNow the the feature-table file is a is a long table containing each of the features annotated in the genome see the top of a file:\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-1_5b50b1293e27cac7ed5f472e9fd1bc55'}\n\n```{.bash .cell-code}\nhead -n 5 data/features/GCF_000009045.1_ASM904v1_feature_table.txt\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n# feature\tclass\tassembly\tassembly_unit\tseq_type\tchromosome\tgenomic_accession\tstart\tend\tstrand\tproduct_accession\tnon-redundant_refseq\trelated_accession\tname\tsymbol\tGeneID\tlocus_tag\tfeature_interval_length\tproduct_length\tattributes\ngene\tprotein_coding\tGCF_000009045.1\tPrimary Assembly\tchromosome\t\tNC_000964.3\t410\t1750\t+\t\t\t\t\tdnaA\t939978\tBSU_00010\t1341\t\told_locus_tag=BSU00010\nCDS\twith_protein\tGCF_000009045.1\tPrimary Assembly\tchromosome\t\tNC_000964.3\t410\t1750\t+\tNP_387882.1\tWP_003242674.1\t\tchromosomal replication initiator informational ATPase\tdnaA\t939978\tBSU_00010\t1341\t446\t\ngene\tprotein_coding\tGCF_000009045.1\tPrimary Assembly\tchromosome\t\tNC_000964.3\t1939\t3075\t+\t\t\t\t\tdnaN\t939970\tBSU_00020\t1137\t\told_locus_tag=BSU00020\nCDS\twith_protein\tGCF_000009045.1\tPrimary Assembly\tchromosome\t\tNC_000964.3\t1939\t3075\t+\tNP_387883.1\tWP_003242509.1\t\tDNA polymerase III (beta subunit)\tdnaN\t939970\tBSU_00020\t1137\t378\t\n```\n:::\n:::\n\n\nThe question now is how to count the lines corresponding to `features` which is the first line. It contains six types of features (CDS, gene, rRNA, tRNA, tmRNA, ncRNA and misc_RNA). This task could be achieved by many ways, but a general approach to count lines is the way through it. Here there three approaches to follow:\n\n:::{.panel-tabset}\n\n### Bash\n\n```{.bash}\n#! usr/bin/bash\n\nexport features=\"id CDS gene ncRNA rRNA tmRNA tRNA\"\n\necho $features\n\n\nfor i in $(ls $1); do\n    values=$(awk '/CDS/{++cnt1} /gene/{++cnt2} /ncRNA/{++cnt3} /rRNA/{++cnt4} /tmRNA/{++cnt5} /tRNA/{++cnt} END {print cnt1, cnt2, cnt3, cnt4, cnt5, cnt6}' ${1}/${i});\n    id=$(egrep -o -m 1 \"GCF.{12}\" ${1}/${i})\n    echo \"$id $values\"\ndone\n```\n\n```\nid CDS gene ncRNA rRNA tmRNA tRNA\nGCF_000009045.1 4238 4578 4 76 2 \nGCF_000146565.1 3998 4120 6 64 2 \nGCF_000186745.1 4111 4247 6 78 2 \nGCF_000209795.2 4262 4400 6 76 2 \nGCF_000227465.1 4167 4314 6 76 2 \nGCF_000227485.1 3991 4128 6 76 2 \nGCF_000293765.1 4205 4343 6 76 2 \nGCF_000321395.1 4043 4179 6 76 2 \n```\n\n### R\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/file-reading_a841374ef486ac2242afc68e062e0b46'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(fs)\n\nall_features <- dir_ls(\"data/features\") |> \n  map_df(read_tsv)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n:::\n\n```{.r .cell-code}\nall_features |> \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 20\n  `# feature` class   assem~1 assem~2 seq_t~3 chrom~4 genom~5 start   end strand\n  <chr>       <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <dbl> <dbl> <chr> \n1 gene        protei~ GCF_00~ Primar~ chromo~ <NA>    NC_000~   410  1750 +     \n2 CDS         with_p~ GCF_00~ Primar~ chromo~ <NA>    NC_000~   410  1750 +     \n3 gene        protei~ GCF_00~ Primar~ chromo~ <NA>    NC_000~  1939  3075 +     \n4 CDS         with_p~ GCF_00~ Primar~ chromo~ <NA>    NC_000~  1939  3075 +     \n5 gene        protei~ GCF_00~ Primar~ chromo~ <NA>    NC_000~  3206  3421 +     \n6 CDS         with_p~ GCF_00~ Primar~ chromo~ <NA>    NC_000~  3206  3421 +     \n# ... with 10 more variables: product_accession <chr>,\n#   `non-redundant_refseq` <chr>, related_accession <lgl>, name <chr>,\n#   symbol <chr>, GeneID <dbl>, locus_tag <chr>, feature_interval_length <dbl>,\n#   product_length <dbl>, attributes <chr>, and abbreviated variable names\n#   1: assembly, 2: assembly_unit, 3: seq_type, 4: chromosome,\n#   5: genomic_accession\n```\n:::\n:::\n\n\nNow that we read all the files into the programming environment we can operate over them with different libraries.\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/data-processing_d1c6c00b5559b2797fd1cbb7be719da1'}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\nall_features_grouped <- all_features |> \n  rename(feature = `# feature`) |> \n  select(assembly, feature) |> \n  group_by(assembly, feature) |>\n  count() |> \n  pivot_wider(names_from = feature, values_from = n)\n\nall_features_grouped\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 8\n# Groups:   assembly [5]\n  assembly          CDS  gene misc_RNA ncRNA  rRNA  tRNA tmRNA\n  <chr>           <int> <int>    <int> <int> <int> <int> <int>\n1 GCF_000009045.1  4237  4536       93     2    30    86    NA\n2 GCF_000146565.1  3998  4104       NA     4    24    77     1\n3 GCF_000186745.1  4111  4230       NA     4    31    83     1\n4 GCF_000209795.2  4262  4384       NA     4    30    87     1\n5 GCF_000227465.1  4167  4294       NA     4    30    92     1\n```\n:::\n:::\n\nThe code lines operation are doing the following steps:\n\n1. Create a new dataset that will group by features per accession.\n2. Change the `# feature` name for simple `feature`.\n3. Select `feature` and `assembly`  columns.\n4. Group by these two columns, enabling grouping operations.\n5. Count the numbers of rows based on the applied grouping.\n6. Generate a wide dataset sending row names as columns.\n\n### Python\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-4_fd6bcc0798d5e34d952ef8952af97dd0'}\n\n```{.python .cell-code}\nimport glob\nimport pandas as pd\n\nfiles = glob.glob(\"data/features/*.txt\")\n\ndf = pd.concat((pd.read_csv(f, sep='\\t') for f in files))\n```\n:::\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-5_f969a6798fe03ae5edd189b786a2cefa'}\n\n```{.python .cell-code}\ndf_renamed  = df.rename(columns={\"# feature\" : \"feature\"})\n```\n:::\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-6_4f5b6326d0d7f6b30e2b8f0d4eb20dc5'}\n\n```{.python .cell-code}\ndf_filtered = df_renamed.filter(items=[\"feature\", \"assembly\"])\n```\n:::\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-7_45ca908e66ee0cdbad9b0cca1b7fe284'}\n\n```{.python .cell-code}\ndf_filtered.groupby([\"assembly\",\"feature\"])[\"feature\"].count()\n```\n:::\n\n\n:::\n\n## Sanger processing\n\nProcessing a Sanger `AB1` file is a very common task in bioinformatics, yet it is sometimes taked for grandted. Many graphical programs allow to process the sequences, yet the task are currently manual involving the trimming and reverse complement generation of the reverse reads (when pair-end sequencing). But, given the vast generation of data on the present, Sanger sequencing is used massively in parallel to generate huge amount of sequences. Therefore, processing \"by-hand\" becomes an unachivable task.\n\nSeveral programs have been developed to automate the processing of sequences, an open source library in `R` is `sangeranalyseR`.\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/libs-_d531c18f4ea5401a3e9aef9481b909e7'}\n\n```{.r .cell-code}\nlibrary(sangeranalyseR)\n```\n:::\n\n\n### Processing a single gene `AB1` pair\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/single-sanger-processing_6b1ed10c6f7e93a8164c79d49bc12d92'}\n\n```{.r .cell-code}\nrpoB <- SangerAlignment(\n  ABIF_Directory = \"data/sanger-seqs/rpoB/\",\n  REGEX_SuffixForward = \"rpoB_1_F.ab1\",\n  REGEX_SuffixReverse = \"rpoB_2_R.ab1\",\n  TrimmingMethod = \"M2\",\n  M2CutoffQualityScore = 33,\n  M2SlidingWindowSize = 5\n)\n\nrpoB\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSangerAlignment S4 instance\n           Input Source :  ABIF \n         Process Method :  REGEX \n         ABIF Directory :  data/sanger-seqs/rpoB/ \n   REGEX Suffix Forward :  rpoB_1_F.ab1 \n   REGEX Suffix Reverse :  rpoB_2_R.ab1 \n      Contigs Consensus :  TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTKGGGGGGGAGWACTTGAGGAGCCATCATCATGAGTGAACGTCTTGTGAAGGATGATGTTTATACATCTATCCATATTGAAGAATATGAATCAGAAGCACGTGATACGAAACTTGGACCTGAAGAAATCACTCGCGATATTCCAAACGTCGGTGAAGATGCGCTTCGCAATCTTGATGACCGCGGAATCATCCGTATTGGGGCAGAAGTAAAAGACGGAGATCTTCTTGTTGGTAAAGTAACGCCTAAAGGTGTAACCGAACTGACTGCTGAAGAACGCCTTCTTCACGCCATCTTTGGTGAAAAAGCCCGCGAGGTTCGTGATACTTCTCTTCGTGTGCCTCACGGCGGCGGCGGAATTATCCACGACGTTAAAGTCTTCAACCGTGAAGACGGAGACGAACTTCCTCCAGGTGTAAACCAGTTGGTACGCGTATATATCGTTCAGAAACGTAAGATTTCTGAAGGGGATAAAATGGCCGGTCGTCACGGTAACAAAGGTGTTATCTCTAAGATTCTTCCTGAAGAGGATATGCCTTACCTTCCTGACGGCACACCAATTGACATCATGCTTAACCCGCTGGGCGTACCATCACGTATGAACATCGGGCAGGTATTGGAGCTTCATATGGGTATGGCCGCTCGTTACCTCGGCATTCACATTGCGTCTCCTGTATTTGATGGAGCGCGAGAAGAGGATGTTTGGGAAACACTTGAAGAAGCCGGCATGTCTCGTGACGCCAAAACGGTGCTTTACGACGGACGTACTGGAGAGCCGTTTGATAACCGCGTGTCTGTCGGTATCATGTACATGATCAAACTGGCACACATGGTTGACGATAAACTTCATGCACGCTCTACAGGTCCTTACTCACTTGTTACGCAGCAGCCTCTTGGCGGTAAAGCGCAATTTGGCGGACAGCGTTTTGGTGAGATGGAGGTTTGGGCACTTGAAGCTTATGGTGCAGCTTACACTCTTCAAGAAATTCTGACTGTTAAGTCCGATAACGTGGTTGGACGTGTGAAACTACACCTCDSTGGCACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA \n```\n:::\n:::\n\n\n This produces an specialized `R` object holding different information from the Sanger processing steps. The entire object can be untangled in a thorough report displaying all the processing information and results using the \n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-10_d980be0b42f4ae340ee1acf8410467bc'}\n\n```{.r .cell-code}\ngenerateReport(rpoB, outputDir = \"data/sanger-processed/\")\n```\n:::\n\n\nAmong the data from the report ypu can see that the unaligned contigs ithere is something called a *Contig Consensus* which is the result of comparing the three consensus out of the **rpoB** genes of the three strains (302, 321, 455). Now, this is not really the sequence we need right away, however we need the separate consensus of each strain gene. To get theme `sangeranalyseR` provide a couple of tools.\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-11_a444182b90043a4ae0552ace39c89ccf'}\n\n```{.r .cell-code}\nwriteFasta(rpoB,\n  outputDir = \"data/sanger-processed/rpoB\",\n  selection = \"contigs_unalignment\",\n)\n```\n:::\n\n\nNow, in the case of the challenge we actually got several genes per strain which is common in molecular biology projects. How do we process all the batch of sequence all at a time? To do so we can split the sequences as folder per gene, then we can use some capabilites of are to iterate an map the sanger processing function to each folder and create a list of processing instances, let's try this out:\n\n### Processing a bulk of `AB1` pair\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/bulk-sanger-processing_f7b369e6e2e2e61482e707cc069cc48f'}\n\n```{.r .cell-code}\nlibrary(fs)\nlibrary(purrr)\n\ndirs <- fs::dir_ls(\"data/sanger-seqs/\")\n\n\nsanger_bulk <- function(dir) {\n  SangerAlignment(\n    ABIF_Directory = dir,\n    REGEX_SuffixForward = \"_1_F.ab1\",\n    REGEX_SuffixReverse = \"_2_R.ab1\",\n    M2CutoffQualityScore = 33,\n    M2SlidingWindowSize = 2\n  )\n}\n\ngenes <- dirs |> \n  map(sanger_bulk)\n\ngenes$\n\ngenes$`data/sanger-seqs/rpoB`\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNULL\n```\n:::\n\n```{.r .cell-code}\ngenes$`data/sanger-seqs/spo0B`\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSangerAlignment S4 instance\n           Input Source :  ABIF \n         Process Method :  REGEX \n         ABIF Directory :  data/sanger-seqs/spo0B \n   REGEX Suffix Forward :  _1_F.ab1 \n   REGEX Suffix Reverse :  _2_R.ab1 \n      Contigs Consensus :  ATCAACCATGCCAGAAAAAAGGAACATGATATTTCTGGGAAAAACMATTGTTTTTCTAACAAAGCCTTACTCTGTTATAATTCATAATACACACTTATACAGACTCCTAAATAAGAAATTAAATGATTGGGAGTGCGAAAATGAAGGATGTTTCAAAAAATCAAGAAGAAAATATAAGCGACACGGCATTAACAAACGAACTGGTTCATCTGCTGGGCCATTCCCGGCATGATTGGATGAATAAGCTGCAGCTGATTAAAGGAAACTTAAGCTTGCAGAAGTATGACCGCGTCTTTGAAATGATTGAAGAAATGGTTATAGACGCGAAGCACGAATCAAAGCTCTCAAACCTAAAAACACCGCATTTGGCGTTTGATTTTCTTACATTTAATTGGAAAACCCATTATATGACGCTTGAATATGAAGTTCTTGGAGAAATTAAGGATTTGTCGGCTTATGATCAAAAGCTGGCAAAACTGATGAGAAAGCTGTTTCATCTGTTTGATCAAGCAGTCAGCAGAGAGAGTGAAAATCATTTAACGGTTTCGCTTCAAACAGATCATCCTGACAGACAGCTGATTCTGTACCTTGATTTTCACGGCGCCTTTGCCGATCCTTCTGCTTTTGATGATATTCGGCAGAATGGATACGAGGATGTGGATATCATGCGTTTTGAGATCACAAGCCACGAATGTCTGATTGTAAATAGGGTTGGTACTAGCGGTAGTTTTTAACGGTTTAGAACGGAGGACATTATGTTTGTAGATCAGGTCAAAGTATATGTAAAAGGCGGCG \n```\n:::\n:::\n\n\nFinally to generate reports we need to call the appropriate instance with the `$` to select the gene we are interested to inspect:\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-13_9111c17521d8f079f1ac0e4e4644cd91'}\n\n```{.r .cell-code}\ngenerateReport(genes$`data/sanger-seqs/spo0B`, outputDir =\"data/sanger-processed/spo0B\")\n\n\nwriteFasta(\n genes$`data/sanger-seqs/rpoB`,\n outputDir = \"data/sanger-processed/rpoB\",\n selection = \"contigs_unalignment\"\n)\n```\n:::\n\n\nNow that we got the actual multifasta of the genes from all strain, the identification process using `blastn` from the command line will follow as:\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-14_59174069756e02e9fe36b12e64ebb45a'}\n\n```{.bash .cell-code}\nblastn -db nr -query rpoB-unaligned-contigs.mfa -out rpoB-blastn-report.txt -remote\n```\n:::\n\n\n\n## Multiple sequence alignment\n\n### Download sequences\n\nMake sure to use the `--flat-output`  avoiding download of multiple metadata\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-15_a58671b0254ab4938cf1bd5a1d934890'}\n\n```{.bash .cell-code}\nngd --flat-output -p 4 -s refseq -A genome-accessions.txt -F cds-fasta bacteria\n```\n:::\n\n\nIn this case `cds-fasta` parameter will download the nucleotide sequences of the gene. Other alternatives could be useful such as blast search on a genome database or searching through the GENBANK annotation files (both files also could be downloaded using `ngd`).\n\n### Unwrapping FASTA records {.unnumbered}\n\nNCBI registries came with an undesirable wrapping around the lines of sequencing which basically is inserting a return character after some established number of characters. Then a way to get rid of them is to use a command line utility from [AstrobioMike (Mike Lee)](https://github.com/AstrobioMike) which will give a line per sequence after the FASTA header. We can later assume the the first line after the header will be the entire sequence\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-16_f02dd8dc690dabc6473144e581881fae'}\n\n```{.bash .cell-code}\nfor i in GCF_*; do \n    N=$(basename $i .fna); \n    bash bit-remove-wraps.sh ${i} > ${N}_unwrapped.fasta; \ndone\n```\n:::\n\n\n### Gene searching\n\nA possible way to search throughout the file registries is by using the `grep` command, that recursively will search each file. Fine tuned it allow to search for the first  match, but also for the \"after-context\" in terms of lines desired to be printed:\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-17_26fcd3b699e4fa08ab45adebf4016699'}\n\n```{.bash .cell-code}\nfor i in *unwrapped*; do grep -A 1 \"gyrA\" $i; done > all-gyrA.fasta\n```\n:::\n\n\nAfter finding the genes, we are now with an almost clean multi-sequence file, because header names are still and will be problematic. How do we programmatically change the FASTA headers? We will see in the next step.\n\nNow the the files has files names that are simply to work with. Which will enable to asses better out sequence alignment matrix.\n\n### Sequence alignment \n\nThere are many programs that are suited for performed multiple sequence alignments. Perhaps the two most used are [`MAFFT`](https://mafft.cbrc.jp/alignment/software/) and [`MUSCLE`](https://drive5.com/muscle5/) both specialized in multiple sequence alignment (that is: when having two or more than two sequences). The second tends to be more accurate when having large data-sets, but the first on is more versatile, fast and accurate on different kind of data-sets. \n\nBoth programs take as input a single file containing all the sequences concatenated horizontally (that is a multi-fasta file) careless of the extension but (MFA, FA, FASTA, FNA, etc). And generate a simple output (whether with the `-o` in `MUSCLE` or to the std output in `MAFFT`)\n    \n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-18_d4646a252de91c68c42f606a865353b7'}\n\n```{.bash .cell-code}\nlinsi --preservecase --reorder all-gyrA-renamed.fasta > all-gyrA-renamed-linsi.fasta # locally \n```\n:::\n\n\n::: {.callout-tip .column-margin}\n\nOther alignment alternatives are:\n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-19_735ddbae4ba75f0416d36ce3c2d0b784'}\n\n```{.bash .cell-code}\nmuscle -i all-gyrA-renamed.fasta -o all-gyrA-renamed-muscle.fasta\n```\n:::\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-20_9b3cf4db6fbd18dc9a30087b14ec7b9f'}\n\n```{.bash .cell-code}\nfamsa -t 8 all-gyrA-renamed.fasta > all-gyrA-renamed-famsa.fasta\n```\n:::\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-21_4484ca7f80b7c5a42e6698dd4da87853'}\n\n```{.bash .cell-code}\nkalign -i all-gyrA-renamed.fasta -o all-gyrA-renamed-kalign.fasta\n```\n:::\n\n\n:::\n\n### Assessment of the alignment\n\nInspection of the alignment is there very first step for assessing its quality. A CDS tends to generate a codon-like alignment starting with the methionine codon (ATG,GTG) and finishing with a stop (TAA, TAG, etc.). Therefore finding this structure when aligning a complete genes is expected. If a middle fraction of the gene is being aligned ORF might not display any stop codon. Verifying a codon-like alignment shows a biological order on the sequences other that mere artifact of the alignment, that is an evolutionary behavior of the sequence. We can do it using [seqfu](https://telatin.github.io/seqfu2/) from the CLI [Fig. @fig-fu-msa-view], or interactively with [AliView](https://github.com/AliView/AliView)\n\n\n![A viusalization of the *gyrA* gene alignment using seqfu multiple sequence alignment viewer](figs/fu-msa-view.png){#fig-fu-msa-view}\n\n\nA second step is to find the variability of the alignment. A simple way to find that is to calculate simpl stats from the alignment (sites, variable sites, As, Ts, etc.). A powerful cli program to do so is [goalign](https://github.com/evolbioinfo/goalign) \n\n\n::: {.cell hash='seq-analysis-challenges_cache/pdf/unnamed-chunk-22_1b432e67077108d8cf3fc9ffc0705c9f'}\n\n```{.bash .cell-code}\ngoalign stats -i all-gyrA-renamed-linsi.fasta\n```\n:::\n\n\n```\nlength\t2508\nnseqs\t8\navgalleles\t1.7400\nvariable sites\t1202\nchar\tnb\tfreq\n-\t273\t0.013606\nA\t6418\t0.319876\nC\t3633\t0.181071\nG\t4755\t0.236992\nT\t4985\t0.248455\nalphabet\tnucleotide\n```\n::: {.callout-tip .column-margin}\nA more in depth analysis of the alignment could be done with [CIAlign](https://github.com/KatyBrown/CIAlign).\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}