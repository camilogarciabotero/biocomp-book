{
  "hash": "42672001ddd258cd03e10837dabfe68d",
  "result": {
    "markdown": "---\nexecute: \n  freeze: auto\nfilters:\n  - code-filename\n  - nutshell\n  - lightbox\n---\n\n\n# Seq. Analysis challenges {.unnumbered}\n\n## Counting features\n\n\nThe first  downloading from NCBI\n\nThe first step in this journey is to download a bunch of sequences programmatically. To do so, we will use the program [ncbi-genome-download](https://github.com/kblin/ncbi-genome-download).\n\nYou could inspect all the options it provides, now we will set our command as the following:\n\n```{.zsh}\n#| echo: true\n#| eval: false\nngd --genera \"Bacillus subtilis\"\\\n    -s refseq\\\n    -l complete\\\n    -o Data\\\n    --flat-output\\\n    --format features\\\n    -n bacteria\\\n    | head -n 5\n```\nTo this date this command will search for 216 complete genome information of *Bacillus subtilis* strains and download the **feature-table** file compressed. So the next step is to decompress all of them:\n\n```{.zsh}\nfor i in *.txt; do\n  gzip -d $i\ndone\n```\nNow the the feature-table file is a is a long table containing each of the features annotated in the genome see the top of a file:\n\n\n::: {.cell hash='demo-genome-searching_cache/pdf/unnamed-chunk-1_19e938d93da5cda2d342bdb5d48da3af'}\n\n```{.bash .cell-code}\nhead -n 5 data/features/GCF_000009045.1_ASM904v1_feature_table.txt\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n# feature\tclass\tassembly\tassembly_unit\tseq_type\tchromosome\tgenomic_accession\tstart\tend\tstrand\tproduct_accession\tnon-redundant_refseq\trelated_accession\tname\tsymbol\tGeneID\tlocus_tag\tfeature_interval_length\tproduct_length\tattributes\ngene\tprotein_coding\tGCF_000009045.1\tPrimary Assembly\tchromosome\t\tNC_000964.3\t410\t1750\t+\t\t\t\t\tdnaA\t939978\tBSU_00010\t1341\t\told_locus_tag=BSU00010\nCDS\twith_protein\tGCF_000009045.1\tPrimary Assembly\tchromosome\t\tNC_000964.3\t410\t1750\t+\tNP_387882.1\tWP_003242674.1\t\tchromosomal replication initiator informational ATPase\tdnaA\t939978\tBSU_00010\t1341\t446\t\ngene\tprotein_coding\tGCF_000009045.1\tPrimary Assembly\tchromosome\t\tNC_000964.3\t1939\t3075\t+\t\t\t\t\tdnaN\t939970\tBSU_00020\t1137\t\told_locus_tag=BSU00020\nCDS\twith_protein\tGCF_000009045.1\tPrimary Assembly\tchromosome\t\tNC_000964.3\t1939\t3075\t+\tNP_387883.1\tWP_003242509.1\t\tDNA polymerase III (beta subunit)\tdnaN\t939970\tBSU_00020\t1137\t378\t\n```\n:::\n:::\n\n\nThe question now is how to count the lines corresponding to `features` which is the first line. It contains six types of features (CDS, gene, rRNA, tRNA, tmRNA, ncRNA and misc_RNA). This task could be achieved by many ways, but a general approach to count lines is the way through it. Here there three approaches to follow:\n\n:::{.panel-tabset}\n\n## Bash\n\n```{.bash}\n#! usr/bin/bash\n\nexport features=\"id CDS gene ncRNA rRNA tmRNA tRNA\"\n\necho $features\n\n\nfor i in $(ls $1); do\n    values=$(awk '/CDS/{++cnt1} /gene/{++cnt2} /ncRNA/{++cnt3} /rRNA/{++cnt4} /tmRNA/{++cnt5} /tRNA/{++cnt} END {print cnt1, cnt2, cnt3, cnt4, cnt5, cnt6}' ${1}/${i});\n    id=$(egrep -o -m 1 \"GCF.{12}\" ${1}/${i})\n    echo \"$id $values\"\ndone\n```\n\n```\nid CDS gene ncRNA rRNA tmRNA tRNA\nGCF_000009045.1 4238 4578 4 76 2 \nGCF_000146565.1 3998 4120 6 64 2 \nGCF_000186745.1 4111 4247 6 78 2 \nGCF_000209795.2 4262 4400 6 76 2 \nGCF_000227465.1 4167 4314 6 76 2 \nGCF_000227485.1 3991 4128 6 76 2 \nGCF_000293765.1 4205 4343 6 76 2 \nGCF_000321395.1 4043 4179 6 76 2 \n```\n\n## R\n\n\n::: {.cell hash='demo-genome-searching_cache/pdf/file-reading_95562a8e297013402a8eeaf9251310df'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(fs)\n\nall_features <- dir_ls(\"data/features\") |> \n  map_df(read_tsv)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: One or more parsing issues, see `problems()` for details\n```\n:::\n\n```{.r .cell-code}\nall_features |> \n  head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 20\n  `# feature` class  assembly assembly_unit seq_type chromosome genomic_accessi~\n  <chr>       <chr>  <chr>    <chr>         <chr>    <chr>      <chr>           \n1 gene        prote~ GCF_000~ Primary Asse~ chromos~ <NA>       NC_000964.3     \n2 CDS         with_~ GCF_000~ Primary Asse~ chromos~ <NA>       NC_000964.3     \n3 gene        prote~ GCF_000~ Primary Asse~ chromos~ <NA>       NC_000964.3     \n4 CDS         with_~ GCF_000~ Primary Asse~ chromos~ <NA>       NC_000964.3     \n5 gene        prote~ GCF_000~ Primary Asse~ chromos~ <NA>       NC_000964.3     \n6 CDS         with_~ GCF_000~ Primary Asse~ chromos~ <NA>       NC_000964.3     \n# ... with 13 more variables: start <dbl>, end <dbl>, strand <chr>,\n#   product_accession <chr>, `non-redundant_refseq` <chr>,\n#   related_accession <lgl>, name <chr>, symbol <chr>, GeneID <dbl>,\n#   locus_tag <chr>, feature_interval_length <dbl>, product_length <dbl>,\n#   attributes <chr>\n```\n:::\n:::\n\n\nNow that we read all the files into the programming environment we can operate over them with different libraries.\n\n::: {.cell hash='demo-genome-searching_cache/pdf/data-processing_befeb56fc6139f820a88593bb26c34a6'}\n\n```{.r .cell-code  code-line-numbers=\"true\"}\nall_features_grouped <- all_features |> \n  rename(feature = `# feature`) |> \n  select(assembly, feature) |> \n  group_by(assembly, feature) |>\n  count() |> \n  pivot_wider(names_from = feature, values_from = n)\n\nall_features_grouped\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 8\n# Groups:   assembly [5]\n  assembly          CDS  gene misc_RNA ncRNA  rRNA  tRNA tmRNA\n  <chr>           <int> <int>    <int> <int> <int> <int> <int>\n1 GCF_000009045.1  4237  4536       93     2    30    86    NA\n2 GCF_000146565.1  3998  4104       NA     4    24    77     1\n3 GCF_000186745.1  4111  4230       NA     4    31    83     1\n4 GCF_000209795.2  4262  4384       NA     4    30    87     1\n5 GCF_000227465.1  4167  4294       NA     4    30    92     1\n```\n:::\n:::\n\nThe code lines operation are doing the following steps:\n\n1. Create a new dataset that will group by features per accession.\n2. Change the `# feature` name for simple `feature`.\n3. Select `feature` and `assembly`  columns.\n4. Group by these two columns, enabling grouping operations.\n5. Count the numbers of rows based on the applied grouping.\n6. Generate a wide dataset sending row names as columns.\n\n## Python\n\n\n::: {.cell hash='demo-genome-searching_cache/pdf/unnamed-chunk-4_f31be4f4a00333489d18bc2df0939595'}\n\n```{.python .cell-code}\nimport glob\nimport pandas as pd\n\nfiles = glob.glob(\"data/features/*.txt\")\n\ndf = pd.concat((pd.read_csv(f, sep='\\t') for f in files))\n```\n:::\n\n::: {.cell hash='demo-genome-searching_cache/pdf/unnamed-chunk-5_aae6976f80b020120071b84d911137b5'}\n\n```{.python .cell-code}\ndf_renamed  <- df.rename(columns={\"# feature\" : \"feature\"})\n```\n:::\n\n::: {.cell hash='demo-genome-searching_cache/pdf/unnamed-chunk-6_71164c182c7a2b7143f68711a8d98e78'}\n\n```{.python .cell-code}\ndf_filtered = df_renamed.filter(items=[\"feature\", \"assembly\"])\n```\n:::\n\n::: {.cell hash='demo-genome-searching_cache/pdf/unnamed-chunk-7_b3ac4f74561cf31cc9d55150c3dd8c3c'}\n\n```{.python .cell-code}\ndf_filtered.groupby([\"assembly\",\"feature\"])[\"feature\"].count()\n```\n:::\n\n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}